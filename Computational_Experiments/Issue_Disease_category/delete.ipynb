{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e16d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack.document_store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfFileReader\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryDocumentStore\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfarm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FARMReader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhaystack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_answers\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haystack.document_store'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfFileReader\n",
    "from haystack.document_store.memory import InMemoryDocumentStore\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.utils import print_answers\n",
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "# define the path of the folder containing PDF files\n",
    "pdf_folder = \"/Users/amin/Desktop/33/test\"\n",
    "\n",
    "# create an in-memory document store\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# loop over all PDF files in the folder and index them in the document store\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filepath = os.path.join(pdf_folder, filename)\n",
    "        # read the PDF file and create a Haystack document\n",
    "        with open(filepath, 'rb') as f:\n",
    "            pdf = PdfFileReader(f)\n",
    "            text = \"\"\n",
    "            for i in range(pdf.getNumPages()):\n",
    "                text += pdf.getPage(i).extractText()\n",
    "            document = {\"text\": text, \"meta\": {\"name\": os.path.splitext(filename)[0]}}\n",
    "            document_store.write_documents([document])\n",
    "\n",
    "# create an ExtractiveQAPipeline with a FARMReader as the document reader\n",
    "reader = FARMReader(model_name_or_path=\"deepset/bert-large-uncased-whole-word-masking-squad2\", use_gpu=False)\n",
    "pipeline = ExtractiveQAPipeline(reader=reader)\n",
    "\n",
    "# define the function to extract disease-related keywords from a text chunk\n",
    "def extract_keywords(text):\n",
    "    n = 3  # number of keywords to extract\n",
    "    # use the ExtractiveQAPipeline to find the answer to the question \"what are the main disease-related keywords?\"\n",
    "    question = \"What are the 3 main disease-related keywords?\"\n",
    "    result = pipeline.run(query=question, documents=[{\"text\": text}], top_k_retriever=1, top_k_reader=1)\n",
    "    answers = result['answers']\n",
    "    # extract the top n keywords from the answer\n",
    "    keywords = re.findall(r'\\b\\w+\\b', answers[0]['answer'])\n",
    "    keywords = keywords[:n]\n",
    "    return keywords\n",
    "\n",
    "# loop over all PDF files in the folder\n",
    "data = []\n",
    "for filename in os.listdir(pdf_folder):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filepath = os.path.join(pdf_folder, filename)\n",
    "        # read the PDF file\n",
    "        with open(filepath, 'rb') as f:\n",
    "            pdf = PdfFileReader(f)\n",
    "            text = \"\"\n",
    "            for i in range(pdf.getNumPages()):\n",
    "                text += pdf.getPage(i).extractText()\n",
    "            # divide the text into chunks of 512 tokens\n",
    "            chunk_size = 512\n",
    "            chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "            # extract disease-related keywords from each chunk\n",
    "            keywords = []\n",
    "            for chunk in chunks:\n",
    "                keywords += extract_keywords(chunk)\n",
    "            # save the file name and keywords in a data frame\n",
    "            data.append([os.path.splitext(filename)[0], keywords])\n",
    "\n",
    "# create a data frame from the collected data\n",
    "df = pd.DataFrame(data, columns=[\"File\", \"Issue_KW\"])\n",
    "\n",
    "# save the data frame to a CSV file\n",
    "df.to_csv(\"Issue_KW.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec429974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Issue_KW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JPM_SRZN_NOTE_11.28.22</td>\n",
       "      <td>[Key, Changes, EPS, 2021A, 2022E, liver, trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CT one-pager Dec 22</td>\n",
       "      <td>[circadian, rhythm, disorders, US, EU, disease...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     File                                           Issue_KW\n",
       "0  JPM_SRZN_NOTE_11.28.22  [Key, Changes, EPS, 2021A, 2022E, liver, trans...\n",
       "1     CT one-pager Dec 22  [circadian, rhythm, disorders, US, EU, disease..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
